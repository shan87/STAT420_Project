\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{unicode=true,
            pdftitle={STAT 420: Data Analysis Project - Predict the price of your dream home},
            pdfauthor={Anupama Agrahari, Dhanendra Singh, Naveen Kumar Palani, Shanthakumar Subramanian},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=cyan,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{STAT 420: Data Analysis Project - Predict the price of your dream home}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Anupama Agrahari, Dhanendra Singh, Naveen Kumar Palani, Shanthakumar
Subramanian}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \date{}
  \predate{}\postdate{}


\begin{document}
\maketitle

\subsection{Team}\label{team}

We are team of four. Please find below our names and Net ID in
alphabetical order.

\begin{longtable}[]{@{}lll@{}}
\toprule
FirstName & LastName & NetID\tabularnewline
\midrule
\endhead
Anupama & Agrahari & anupama3\tabularnewline
Dhanendra & Singh & disingh2\tabularnewline
Naveen Kumar & Palani & npalani3\tabularnewline
Shanthakumar & Subramanian & SS81\tabularnewline
\bottomrule
\end{longtable}

\subsection{Introduction}\label{introduction}

\subsubsection{About the Project}\label{about-the-project}

This data analysis project is inspired from the House Prices: Advanced
Regression Techniques competition held in Kaggle.

In this project we are building a model to predict the SalePrice of each
home, based on the 80 explanatory variables describing (almost) every
aspect of residential homes in Ames, Iowa.

\subsubsection{Data Set}\label{data-set}

\paragraph{Source}\label{source}

Below are the details about our dataset. We are using house prie data
available at
\url{https://www.kaggle.com/c/house-prices-advanced-regression-techniques}
. We will use regression techniques to predict the SalePrice.

\paragraph{Background}\label{background}

The Ames Housing dataset was compiled by Dean De Cock for use in data
science education. It's an incredible alternative for data scientists
looking for a modernized and expanded version of the often cited Boston
Housing dataset.

\paragraph{File descriptions}\label{file-descriptions}

List of files used in the project

\begin{itemize}
\tightlist
\item
  train.csv - the training set
\item
  test.csv - the test set
\item
  data\_description.txt - full description of each column, originally
  prepared by Dean De Cock but lightly edited to match the column names
  used here
\end{itemize}

\paragraph{Data fields}\label{data-fields}

Here's a brief description of different fields of the house data set.

\begin{itemize}
\tightlist
\item
  SalePrice - The property's sale price in dollars. This is the target
  variable that we are trying to predict.
\item
  MSSubClass: The building class
\item
  MSZoning: The general zoning classification
\item
  LotFrontage: Linear feet of street connected to property
\item
  LotArea: Lot size in square feet
\item
  Street: Type of road access
\item
  Alley: Type of alley access
\item
  LotShape: General shape of property
\item
  LandContour: Flatness of the property
\item
  Utilities: Type of utilities available
\item
  LotConfig: Lot configuration
\item
  LandSlope: Slope of property
\item
  Neighborhood: Physical locations within Ames city limits
\item
  Condition1: Proximity to main road or railroad
\item
  Condition2: Proximity to main road or railroad (if a second is
  present)
\item
  BldgType: Type of dwelling
\item
  HouseStyle: Style of dwelling
\item
  OverallQual: Overall material and finish quality
\item
  OverallCond: Overall condition rating
\item
  YearBuilt: Original construction date
\item
  YearRemodAdd: Remodel date
\item
  RoofStyle: Type of roof
\item
  RoofMatl: Roof material
\item
  Exterior1st: Exterior covering on house
\item
  Exterior2nd: Exterior covering on house (if more than one material)
\item
  MasVnrType: Masonry veneer type
\item
  MasVnrArea: Masonry veneer area in square feet
\item
  ExterQual: Exterior material quality
\item
  ExterCond: Present condition of the material on the exterior
\item
  Foundation: Type of foundation
\item
  BsmtQual: Height of the basement
\item
  BsmtCond: General condition of the basement
\item
  BsmtExposure: Walkout or garden level basement walls
\item
  BsmtFinType1: Quality of basement finished area
\item
  BsmtFinSF1: Type 1 finished square feet
\item
  BsmtFinType2: Quality of second finished area (if present)
\item
  BsmtFinSF2: Type 2 finished square feet
\item
  BsmtUnfSF: Unfinished square feet of basement area
\item
  TotalBsmtSF: Total square feet of basement area
\item
  Heating: Type of heating
\item
  HeatingQC: Heating quality and condition
\item
  CentralAir: Central air conditioning
\item
  Electrical: Electrical system
\item
  X1stFlrSF: First Floor square feet
\item
  X2ndFlrSF: Second floor square feet
\item
  LowQualFinSF: Low quality finished square feet (all floors)
\item
  GrLivArea: Above grade (ground) living area square feet
\item
  BsmtFullBath: Basement full bathrooms
\item
  BsmtHalfBath: Basement half bathrooms
\item
  FullBath: Full bathrooms above grade
\item
  HalfBath: Half baths above grade
\item
  Bedroom: Number of bedrooms above basement level
\item
  Kitchen: Number of kitchens
\item
  KitchenQual: Kitchen quality
\item
  TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)
\item
  Functional: Home functionality rating
\item
  Fireplaces: Number of fireplaces
\item
  FireplaceQu: Fireplace quality
\item
  GarageType: Garage location
\item
  GarageYrBlt: Year garage was built
\item
  GarageFinish: Interior finish of the garage
\item
  GarageCars: Size of garage in car capacity
\item
  GarageArea: Size of garage in square feet
\item
  GarageQual: Garage quality
\item
  GarageCond: Garage condition
\item
  PavedDrive: Paved driveway
\item
  WoodDeckSF: Wood deck area in square feet
\item
  OpenPorchSF: Open porch area in square feet
\item
  EnclosedPorch: Enclosed porch area in square feet
\item
  3SsnPorch: Three season porch area in square feet
\item
  ScreenPorch: Screen porch area in square feet
\item
  PoolArea: Pool area in square feet
\item
  PoolQC: Pool quality
\item
  Fence: Fence quality
\item
  MiscFeature: Miscellaneous feature not covered in other categories
\item
  MiscVal: \$Value of miscellaneous feature
\item
  MoSold: Month Sold
\item
  YrSold: Year Sold
\item
  SaleType: Type of sale
\item
  SaleCondition: Condition of sale
\end{itemize}

\subsection{Data Preparation}\label{data-preparation}

\subsubsection{Data Import}\label{data-import}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Libraries used}

\KeywordTok{library}\NormalTok{(lmtest)}
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{library}\NormalTok{(formattable)}
\KeywordTok{library}\NormalTok{(faraway)}
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(leaps)}
\KeywordTok{library}\NormalTok{(caret)}
\KeywordTok{library}\NormalTok{(tinytex)}
\end{Highlighting}
\end{Shaded}

\textbf{Importing test and train data from the files}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Import train and test dataset from the source files.}

\NormalTok{train =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"train.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{) }
\NormalTok{test =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"test.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Checking the number of columns and observation in test and train
data}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1460   81
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1459   80
\end{verbatim}

From the dimension of test and train data, we could see that the test
data has one less column than the train, as the \textbf{Sale Price}
column would not be availble in test data and that's what we will be
predicting as part of this project.

\subsubsection{Data Cleansing}\label{data-cleansing}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Displaying the structure of train dataset}

\KeywordTok{str}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1460 obs. of  81 variables:
##  $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ MSSubClass   : int  60 20 60 70 60 50 20 60 50 190 ...
##  $ MSZoning     : chr  "RL" "RL" "RL" "RL" ...
##  $ LotFrontage  : int  65 80 68 60 84 85 75 NA 51 50 ...
##  $ LotArea      : int  8450 9600 11250 9550 14260 14115 10084 10382 6120 7420 ...
##  $ Street       : chr  "Pave" "Pave" "Pave" "Pave" ...
##  $ Alley        : chr  NA NA NA NA ...
##  $ LotShape     : chr  "Reg" "Reg" "IR1" "IR1" ...
##  $ LandContour  : chr  "Lvl" "Lvl" "Lvl" "Lvl" ...
##  $ Utilities    : chr  "AllPub" "AllPub" "AllPub" "AllPub" ...
##  $ LotConfig    : chr  "Inside" "FR2" "Inside" "Corner" ...
##  $ LandSlope    : chr  "Gtl" "Gtl" "Gtl" "Gtl" ...
##  $ Neighborhood : chr  "CollgCr" "Veenker" "CollgCr" "Crawfor" ...
##  $ Condition1   : chr  "Norm" "Feedr" "Norm" "Norm" ...
##  $ Condition2   : chr  "Norm" "Norm" "Norm" "Norm" ...
##  $ BldgType     : chr  "1Fam" "1Fam" "1Fam" "1Fam" ...
##  $ HouseStyle   : chr  "2Story" "1Story" "2Story" "2Story" ...
##  $ OverallQual  : int  7 6 7 7 8 5 8 7 7 5 ...
##  $ OverallCond  : int  5 8 5 5 5 5 5 6 5 6 ...
##  $ YearBuilt    : int  2003 1976 2001 1915 2000 1993 2004 1973 1931 1939 ...
##  $ YearRemodAdd : int  2003 1976 2002 1970 2000 1995 2005 1973 1950 1950 ...
##  $ RoofStyle    : chr  "Gable" "Gable" "Gable" "Gable" ...
##  $ RoofMatl     : chr  "CompShg" "CompShg" "CompShg" "CompShg" ...
##  $ Exterior1st  : chr  "VinylSd" "MetalSd" "VinylSd" "Wd Sdng" ...
##  $ Exterior2nd  : chr  "VinylSd" "MetalSd" "VinylSd" "Wd Shng" ...
##  $ MasVnrType   : chr  "BrkFace" "None" "BrkFace" "None" ...
##  $ MasVnrArea   : int  196 0 162 0 350 0 186 240 0 0 ...
##  $ ExterQual    : chr  "Gd" "TA" "Gd" "TA" ...
##  $ ExterCond    : chr  "TA" "TA" "TA" "TA" ...
##  $ Foundation   : chr  "PConc" "CBlock" "PConc" "BrkTil" ...
##  $ BsmtQual     : chr  "Gd" "Gd" "Gd" "TA" ...
##  $ BsmtCond     : chr  "TA" "TA" "TA" "Gd" ...
##  $ BsmtExposure : chr  "No" "Gd" "Mn" "No" ...
##  $ BsmtFinType1 : chr  "GLQ" "ALQ" "GLQ" "ALQ" ...
##  $ BsmtFinSF1   : int  706 978 486 216 655 732 1369 859 0 851 ...
##  $ BsmtFinType2 : chr  "Unf" "Unf" "Unf" "Unf" ...
##  $ BsmtFinSF2   : int  0 0 0 0 0 0 0 32 0 0 ...
##  $ BsmtUnfSF    : int  150 284 434 540 490 64 317 216 952 140 ...
##  $ TotalBsmtSF  : int  856 1262 920 756 1145 796 1686 1107 952 991 ...
##  $ Heating      : chr  "GasA" "GasA" "GasA" "GasA" ...
##  $ HeatingQC    : chr  "Ex" "Ex" "Ex" "Gd" ...
##  $ CentralAir   : chr  "Y" "Y" "Y" "Y" ...
##  $ Electrical   : chr  "SBrkr" "SBrkr" "SBrkr" "SBrkr" ...
##  $ X1stFlrSF    : int  856 1262 920 961 1145 796 1694 1107 1022 1077 ...
##  $ X2ndFlrSF    : int  854 0 866 756 1053 566 0 983 752 0 ...
##  $ LowQualFinSF : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ GrLivArea    : int  1710 1262 1786 1717 2198 1362 1694 2090 1774 1077 ...
##  $ BsmtFullBath : int  1 0 1 1 1 1 1 1 0 1 ...
##  $ BsmtHalfBath : int  0 1 0 0 0 0 0 0 0 0 ...
##  $ FullBath     : int  2 2 2 1 2 1 2 2 2 1 ...
##  $ HalfBath     : int  1 0 1 0 1 1 0 1 0 0 ...
##  $ BedroomAbvGr : int  3 3 3 3 4 1 3 3 2 2 ...
##  $ KitchenAbvGr : int  1 1 1 1 1 1 1 1 2 2 ...
##  $ KitchenQual  : chr  "Gd" "TA" "Gd" "Gd" ...
##  $ TotRmsAbvGrd : int  8 6 6 7 9 5 7 7 8 5 ...
##  $ Functional   : chr  "Typ" "Typ" "Typ" "Typ" ...
##  $ Fireplaces   : int  0 1 1 1 1 0 1 2 2 2 ...
##  $ FireplaceQu  : chr  NA "TA" "TA" "Gd" ...
##  $ GarageType   : chr  "Attchd" "Attchd" "Attchd" "Detchd" ...
##  $ GarageYrBlt  : int  2003 1976 2001 1998 2000 1993 2004 1973 1931 1939 ...
##  $ GarageFinish : chr  "RFn" "RFn" "RFn" "Unf" ...
##  $ GarageCars   : int  2 2 2 3 3 2 2 2 2 1 ...
##  $ GarageArea   : int  548 460 608 642 836 480 636 484 468 205 ...
##  $ GarageQual   : chr  "TA" "TA" "TA" "TA" ...
##  $ GarageCond   : chr  "TA" "TA" "TA" "TA" ...
##  $ PavedDrive   : chr  "Y" "Y" "Y" "Y" ...
##  $ WoodDeckSF   : int  0 298 0 0 192 40 255 235 90 0 ...
##  $ OpenPorchSF  : int  61 0 42 35 84 30 57 204 0 4 ...
##  $ EnclosedPorch: int  0 0 0 272 0 0 0 228 205 0 ...
##  $ X3SsnPorch   : int  0 0 0 0 0 320 0 0 0 0 ...
##  $ ScreenPorch  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolArea     : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolQC       : chr  NA NA NA NA ...
##  $ Fence        : chr  NA NA NA NA ...
##  $ MiscFeature  : chr  NA NA NA NA ...
##  $ MiscVal      : int  0 0 0 0 0 700 0 350 0 0 ...
##  $ MoSold       : int  2 5 9 2 12 10 8 11 4 1 ...
##  $ YrSold       : int  2008 2007 2008 2006 2008 2009 2007 2009 2008 2008 ...
##  $ SaleType     : chr  "WD" "WD" "WD" "WD" ...
##  $ SaleCondition: chr  "Normal" "Normal" "Normal" "Abnorml" ...
##  $ SalePrice    : int  208500 181500 223500 140000 250000 143000 307000 200000 129900 118000 ...
\end{verbatim}

From the above,\texttt{str} display of data, we could see the below
issues:

\begin{itemize}
\tightlist
\item
  The data is not completely clean, certain variables contain
  \texttt{NA} values which could cause problems when we do any
  mathematical operation and while fitting the model.
\item
  The levels of some of the factor variables are not the same across the
  training set and test set, which might also cause some problems while
  fitting the model.
\item
  Some of the categoricals variables are listed as numeric, this might
  have some impact on fitting the model.
\end{itemize}

We will do the following to rectify the above issues:

\begin{itemize}
\tightlist
\item
  Remove NA and update the values with ``None'' for character variables.
\item
  Impute/replce NA with either \texttt{0}, \texttt{Mean},
  \texttt{Medain} or \texttt{Mode} for numeric variables appropriatley.
\end{itemize}

We should make sure that, the train and test sets have the same factor
levels by loading each data set again without converting strings to
factors, combining them into one large data set, converting strings to
factors for the combined data set and then separating them.

We also can change the data types of the below features from numeric to
string.

\texttt{MSSubClass}, \texttt{OverallCond}, \texttt{OverallQual},
\texttt{GarageCars}, \texttt{YrSold}, \texttt{MoSold}

The values for each feature above represent different categories and not
different amounts of something. This is easiest to see in the case of
MSSubClass, where the numbers encode different categories of houses,
such as 2-Story 1946 and Newer (60) and 2-Story 1945 and Older (70). It
is harder to discern in a feature like GarageCars, where each value
seems to count something (cars) but in actuality represents the garage
capacity, and therefore represents a category.

\paragraph{Step 1}\label{step-1}

Removing the target variable SalePrice, which is not found in test data
set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## Removing the target variable saleprice}

\NormalTok{SalePrice =}\StringTok{ }\NormalTok{train}\OperatorTok{$}\NormalTok{SalePrice }
\NormalTok{train}\OperatorTok{$}\NormalTok{SalePrice =}\StringTok{ }\OtherTok{NULL}
\end{Highlighting}
\end{Shaded}

\paragraph{Step 2}\label{step-2}

Combining test and training data set and changing numeric to factor
variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Combine data sets}

\NormalTok{house_data =}\StringTok{ }\KeywordTok{rbind}\NormalTok{(train,test)}

\NormalTok{##Change Numeric to factor}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{MSSubClass =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{MSSubClass)}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{OverallCond =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{OverallCond)}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{OverallQual =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{OverallQual)}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{GarageCars =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{GarageCars)}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{YrSold =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{YrSold)}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{MoSold =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{MoSold)}
\end{Highlighting}
\end{Shaded}

\paragraph{Step 3}\label{step-3}

We will now convert \texttt{character} columns to factor and will
replace NA values with ``None''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## Replacing the NA in character variable with None.}

\ControlFlowTok{for}\NormalTok{ (col }\ControlFlowTok{in} \KeywordTok{colnames}\NormalTok{(house_data))\{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{typeof}\NormalTok{(house_data[,col]) }\OperatorTok{==}\StringTok{ "character"}\NormalTok{)\{}
\NormalTok{    new_col =}\StringTok{ }\NormalTok{house_data[,col]}
\NormalTok{    new_col[}\KeywordTok{is.na}\NormalTok{(new_col)] =}\StringTok{ "None"}
\NormalTok{    house_data[col] =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(new_col)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now the \texttt{factor\ variable} should be common across test and train
dataset.

\paragraph{Step 4}\label{step-4}

Lets try to find the missing values in \texttt{integer\ variable} and
fix it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## Checking for missing data values in all integer variables}

\NormalTok{Missing_indices =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(house_data,}\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(x)))}
\NormalTok{Missing_Summary =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{index =} \KeywordTok{names}\NormalTok{(house_data),}\DataTypeTok{Missing_Values=}\NormalTok{Missing_indices)}
\NormalTok{Missing_Summary[Missing_Summary}\OperatorTok{$}\NormalTok{Missing_Values }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     index Missing_Values
## LotFrontage   LotFrontage            486
## MasVnrArea     MasVnrArea             23
## BsmtFinSF1     BsmtFinSF1              1
## BsmtFinSF2     BsmtFinSF2              1
## BsmtUnfSF       BsmtUnfSF              1
## TotalBsmtSF   TotalBsmtSF              1
## BsmtFullBath BsmtFullBath              2
## BsmtHalfBath BsmtHalfBath              2
## GarageYrBlt   GarageYrBlt            159
## GarageArea     GarageArea              1
\end{verbatim}

Above are the list of variable having NA values, in the below section,
we will fix those values with relavant values

\begin{itemize}
\item
  Imputed missing values of \texttt{MasVnrArea} with its \texttt{mean}.
\item
  Imputed missing values of \texttt{LotFrontage} with its
  \texttt{median}
\item
  Imputed the missing values of below with \texttt{0}.
\item
  \texttt{GarageYrBlt}, \texttt{BsmtFullBath}, \texttt{BsmtHalfBath},
  \texttt{BsmtUnfSF}, \texttt{BsmtFinSF1}, \texttt{BsmtFinSF2},
  \texttt{GarageArea}, \texttt{GarageCars}, \texttt{TotalBsmtSF}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## Impute Mean}
\NormalTok{house_data}\OperatorTok{$}\NormalTok{MasVnrArea[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{MasVnrArea))] =}\StringTok{ }\KeywordTok{mean}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{MasVnrArea,}\DataTypeTok{na.rm=}\NormalTok{T)}

\NormalTok{## Impute Median}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{LotFrontage[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{LotFrontage))] =}\StringTok{ }\KeywordTok{median}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{LotFrontage,}\DataTypeTok{na.rm =}\NormalTok{ T)}

\NormalTok{## Impute 0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{GarageYrBlt[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{GarageYrBlt))] =}\StringTok{ }\DecValTok{0} 

\NormalTok{house_data}\OperatorTok{$}\NormalTok{BsmtFullBath[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{BsmtFullBath ))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{BsmtHalfBath[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{BsmtHalfBath ))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{BsmtUnfSF[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{BsmtUnfSF))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{BsmtFinSF1[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{BsmtFinSF1))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{BsmtFinSF2[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{BsmtFinSF2))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{GarageArea[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{GarageArea))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{GarageCars[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{GarageCars))] =}\StringTok{ }\DecValTok{0}

\NormalTok{house_data}\OperatorTok{$}\NormalTok{TotalBsmtSF[}\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(house_data}\OperatorTok{$}\NormalTok{TotalBsmtSF))] =}\StringTok{ }\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\paragraph{Step 5}\label{step-5}

We will split the train and test data now as the data issues are fixed.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Separate out our train and test sets}

\NormalTok{train =}\StringTok{ }\NormalTok{house_data[}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train),]}
\NormalTok{train}\OperatorTok{$}\NormalTok{SalePrice =}\StringTok{ }\NormalTok{SalePrice  }
\NormalTok{test =}\StringTok{ }\NormalTok{house_data[(}\KeywordTok{nrow}\NormalTok{(train)}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(house_data),]}
\end{Highlighting}
\end{Shaded}

Let's now have a look at the train data set

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Displaying the train dataset structure after data cleansing.}

\KeywordTok{str}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1460 obs. of  81 variables:
##  $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ MSSubClass   : Factor w/ 16 levels "120","150","160",..: 11 6 11 12 11 10 6 11 10 5 ...
##  $ MSZoning     : Factor w/ 6 levels "C (all)","FV",..: 5 5 5 5 5 5 5 5 6 5 ...
##  $ LotFrontage  : int  65 80 68 60 84 85 75 68 51 50 ...
##  $ LotArea      : int  8450 9600 11250 9550 14260 14115 10084 10382 6120 7420 ...
##  $ Street       : Factor w/ 2 levels "Grvl","Pave": 2 2 2 2 2 2 2 2 2 2 ...
##  $ Alley        : Factor w/ 3 levels "Grvl","None",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ LotShape     : Factor w/ 4 levels "IR1","IR2","IR3",..: 4 4 1 1 1 1 4 1 4 4 ...
##  $ LandContour  : Factor w/ 4 levels "Bnk","HLS","Low",..: 4 4 4 4 4 4 4 4 4 4 ...
##  $ Utilities    : Factor w/ 3 levels "AllPub","None",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ LotConfig    : Factor w/ 5 levels "Corner","CulDSac",..: 5 3 5 1 3 5 5 1 5 1 ...
##  $ LandSlope    : Factor w/ 3 levels "Gtl","Mod","Sev": 1 1 1 1 1 1 1 1 1 1 ...
##  $ Neighborhood : Factor w/ 25 levels "Blmngtn","Blueste",..: 6 25 6 7 14 12 21 17 18 4 ...
##  $ Condition1   : Factor w/ 9 levels "Artery","Feedr",..: 3 2 3 3 3 3 3 5 1 1 ...
##  $ Condition2   : Factor w/ 8 levels "Artery","Feedr",..: 3 3 3 3 3 3 3 3 3 1 ...
##  $ BldgType     : Factor w/ 5 levels "1Fam","2fmCon",..: 1 1 1 1 1 1 1 1 1 2 ...
##  $ HouseStyle   : Factor w/ 8 levels "1.5Fin","1.5Unf",..: 6 3 6 6 6 1 3 6 1 2 ...
##  $ OverallQual  : Factor w/ 10 levels "1","10","2","3",..: 8 7 8 8 9 6 9 8 8 6 ...
##  $ OverallCond  : Factor w/ 9 levels "1","2","3","4",..: 5 8 5 5 5 5 5 6 5 6 ...
##  $ YearBuilt    : int  2003 1976 2001 1915 2000 1993 2004 1973 1931 1939 ...
##  $ YearRemodAdd : int  2003 1976 2002 1970 2000 1995 2005 1973 1950 1950 ...
##  $ RoofStyle    : Factor w/ 6 levels "Flat","Gable",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ RoofMatl     : Factor w/ 8 levels "ClyTile","CompShg",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ Exterior1st  : Factor w/ 16 levels "AsbShng","AsphShn",..: 14 9 14 15 14 14 14 7 4 9 ...
##  $ Exterior2nd  : Factor w/ 17 levels "AsbShng","AsphShn",..: 15 9 15 17 15 15 15 7 17 9 ...
##  $ MasVnrType   : Factor w/ 4 levels "BrkCmn","BrkFace",..: 2 3 2 3 2 3 4 4 3 3 ...
##  $ MasVnrArea   : num  196 0 162 0 350 0 186 240 0 0 ...
##  $ ExterQual    : Factor w/ 4 levels "Ex","Fa","Gd",..: 3 4 3 4 3 4 3 4 4 4 ...
##  $ ExterCond    : Factor w/ 5 levels "Ex","Fa","Gd",..: 5 5 5 5 5 5 5 5 5 5 ...
##  $ Foundation   : Factor w/ 6 levels "BrkTil","CBlock",..: 3 2 3 1 3 6 3 2 1 1 ...
##  $ BsmtQual     : Factor w/ 5 levels "Ex","Fa","Gd",..: 3 3 3 5 3 3 1 3 5 5 ...
##  $ BsmtCond     : Factor w/ 5 levels "Fa","Gd","None",..: 5 5 5 2 5 5 5 5 5 5 ...
##  $ BsmtExposure : Factor w/ 5 levels "Av","Gd","Mn",..: 4 2 3 4 1 4 1 3 4 4 ...
##  $ BsmtFinType1 : Factor w/ 7 levels "ALQ","BLQ","GLQ",..: 3 1 3 1 3 3 3 1 7 3 ...
##  $ BsmtFinSF1   : num  706 978 486 216 655 ...
##  $ BsmtFinType2 : Factor w/ 7 levels "ALQ","BLQ","GLQ",..: 7 7 7 7 7 7 7 2 7 7 ...
##  $ BsmtFinSF2   : num  0 0 0 0 0 0 0 32 0 0 ...
##  $ BsmtUnfSF    : num  150 284 434 540 490 64 317 216 952 140 ...
##  $ TotalBsmtSF  : num  856 1262 920 756 1145 ...
##  $ Heating      : Factor w/ 6 levels "Floor","GasA",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ HeatingQC    : Factor w/ 5 levels "Ex","Fa","Gd",..: 1 1 1 3 1 1 1 1 3 1 ...
##  $ CentralAir   : Factor w/ 2 levels "N","Y": 2 2 2 2 2 2 2 2 2 2 ...
##  $ Electrical   : Factor w/ 6 levels "FuseA","FuseF",..: 6 6 6 6 6 6 6 6 2 6 ...
##  $ X1stFlrSF    : int  856 1262 920 961 1145 796 1694 1107 1022 1077 ...
##  $ X2ndFlrSF    : int  854 0 866 756 1053 566 0 983 752 0 ...
##  $ LowQualFinSF : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ GrLivArea    : int  1710 1262 1786 1717 2198 1362 1694 2090 1774 1077 ...
##  $ BsmtFullBath : num  1 0 1 1 1 1 1 1 0 1 ...
##  $ BsmtHalfBath : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ FullBath     : int  2 2 2 1 2 1 2 2 2 1 ...
##  $ HalfBath     : int  1 0 1 0 1 1 0 1 0 0 ...
##  $ BedroomAbvGr : int  3 3 3 3 4 1 3 3 2 2 ...
##  $ KitchenAbvGr : int  1 1 1 1 1 1 1 1 2 2 ...
##  $ KitchenQual  : Factor w/ 5 levels "Ex","Fa","Gd",..: 3 5 3 3 3 5 3 5 5 5 ...
##  $ TotRmsAbvGrd : int  8 6 6 7 9 5 7 7 8 5 ...
##  $ Functional   : Factor w/ 8 levels "Maj1","Maj2",..: 8 8 8 8 8 8 8 8 3 8 ...
##  $ Fireplaces   : int  0 1 1 1 1 0 1 2 2 2 ...
##  $ FireplaceQu  : Factor w/ 6 levels "Ex","Fa","Gd",..: 4 6 6 3 6 4 3 6 6 6 ...
##  $ GarageType   : Factor w/ 7 levels "2Types","Attchd",..: 2 2 2 6 2 2 2 2 6 2 ...
##  $ GarageYrBlt  : num  2003 1976 2001 1998 2000 ...
##  $ GarageFinish : Factor w/ 4 levels "Fin","None","RFn",..: 3 3 3 4 3 4 3 3 4 3 ...
##  $ GarageCars   : Factor w/ 7 levels "0","1","2","3",..: 3 3 3 4 4 3 3 3 3 2 ...
##  $ GarageArea   : num  548 460 608 642 836 480 636 484 468 205 ...
##  $ GarageQual   : Factor w/ 6 levels "Ex","Fa","Gd",..: 6 6 6 6 6 6 6 6 2 3 ...
##  $ GarageCond   : Factor w/ 6 levels "Ex","Fa","Gd",..: 6 6 6 6 6 6 6 6 6 6 ...
##  $ PavedDrive   : Factor w/ 3 levels "N","P","Y": 3 3 3 3 3 3 3 3 3 3 ...
##  $ WoodDeckSF   : int  0 298 0 0 192 40 255 235 90 0 ...
##  $ OpenPorchSF  : int  61 0 42 35 84 30 57 204 0 4 ...
##  $ EnclosedPorch: int  0 0 0 272 0 0 0 228 205 0 ...
##  $ X3SsnPorch   : int  0 0 0 0 0 320 0 0 0 0 ...
##  $ ScreenPorch  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolArea     : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolQC       : Factor w/ 4 levels "Ex","Fa","Gd",..: 4 4 4 4 4 4 4 4 4 4 ...
##  $ Fence        : Factor w/ 5 levels "GdPrv","GdWo",..: 5 5 5 5 5 3 5 5 5 5 ...
##  $ MiscFeature  : Factor w/ 5 levels "Gar2","None",..: 2 2 2 2 2 4 2 4 2 2 ...
##  $ MiscVal      : int  0 0 0 0 0 700 0 350 0 0 ...
##  $ MoSold       : Factor w/ 12 levels "1","10","11",..: 5 8 12 5 4 2 11 3 7 1 ...
##  $ YrSold       : Factor w/ 5 levels "2006","2007",..: 3 2 3 1 3 4 2 4 3 3 ...
##  $ SaleType     : Factor w/ 10 levels "COD","Con","ConLD",..: 10 10 10 10 10 10 10 10 10 10 ...
##  $ SaleCondition: Factor w/ 6 levels "Abnorml","AdjLand",..: 5 5 5 1 5 5 5 5 1 5 ...
##  $ SalePrice    : int  208500 181500 223500 140000 250000 143000 307000 200000 129900 118000 ...
\end{verbatim}

From the above \texttt{str} of train dataset, we could see that the
\texttt{NA} in the dataset is completely removed now.

\subsubsection{Train and Test data
Split}\label{train-and-test-data-split}

We can split the data from the train dataset in 80 - 20 ratio, we can
use this 20\% data of train dataset to test our fitted model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Splitting the train dataset into train and test}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{house_trn_idx =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train), }\DecValTok{1168}\NormalTok{)}
\NormalTok{house_trn =}\StringTok{ }\NormalTok{train[house_trn_idx,]}
\NormalTok{house_tst =}\StringTok{ }\NormalTok{train[}\OperatorTok{-}\NormalTok{house_trn_idx,]}
\end{Highlighting}
\end{Shaded}

\subsection{Exploratory Data Analysis}\label{exploratory-data-analysis}

\subsubsection{Correlation Matrix}\label{correlation-matrix}

Lets plot the correlation matrix to see which variables have
multicollinearity.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Correlation Plot}

\NormalTok{house_train_num<-house_trn[, }\KeywordTok{sapply}\NormalTok{(house_trn, is.numeric)]}
\NormalTok{Correlation<-}\KeywordTok{cor}\NormalTok{(}\KeywordTok{na.omit}\NormalTok{(house_train_num))}
\KeywordTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## corrplot 0.84 loaded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{corrplot}\NormalTok{(Correlation, }\DataTypeTok{method =} \StringTok{"square"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-14-1.pdf}

From the above plot, we could see that some varaiables have high
correlation between each other, below are the few examples:

\begin{itemize}
\tightlist
\item
  TotalBsmtSF and X1stFlrSF
\item
  BsmtFinSF1 and BsmtFullBath
\item
  X2ndFlrSF and GrLivArea
\end{itemize}

\subsubsection{Correlation with
SalePrice}\label{correlation-with-saleprice}

We will explore the Variable which has correlation of more than
\texttt{0.5} with SalePrice.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#variables having Correlation > 0.5 with SalePrice  }

\ControlFlowTok{for}\NormalTok{ (col }\ControlFlowTok{in} \KeywordTok{colnames}\NormalTok{(house_trn))\{}
   \ControlFlowTok{if}\NormalTok{(}\KeywordTok{is.numeric}\NormalTok{(house_trn[,col]))\{}
       \ControlFlowTok{if}\NormalTok{( }\KeywordTok{abs}\NormalTok{(}\KeywordTok{cor}\NormalTok{(house_trn[,col],house_trn}\OperatorTok{$}\NormalTok{SalePrice)) }\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{)\{}
           \KeywordTok{print}\NormalTok{(col)}
           \KeywordTok{print}\NormalTok{( }\KeywordTok{cor}\NormalTok{(house_trn[,col],house_trn}\OperatorTok{$}\NormalTok{SalePrice))}
\NormalTok{         \}}
\NormalTok{   \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "YearBuilt"
## [1] 0.5250568
## [1] "YearRemodAdd"
## [1] 0.5130786
## [1] "TotalBsmtSF"
## [1] 0.6130396
## [1] "X1stFlrSF"
## [1] 0.6046266
## [1] "GrLivArea"
## [1] 0.7103528
## [1] "FullBath"
## [1] 0.5632221
## [1] "TotRmsAbvGrd"
## [1] 0.525106
## [1] "GarageArea"
## [1] 0.6172792
## [1] "SalePrice"
## [1] 1
\end{verbatim}

We can use the variable listed above to fit our model as it has high
corelation with sales price.

\subsubsection{Distribtion of SalePrice}\label{distribtion-of-saleprice}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Distribution of SalePrice}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\KeywordTok{hist}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice,}
    \DataTypeTok{xlab   =} \StringTok{"Sale Price without log(SalePrice)"}\NormalTok{,}
    \DataTypeTok{main   =} \StringTok{"Histogram of sales price"}\NormalTok{,}
    \DataTypeTok{border =} \StringTok{"blue"}\NormalTok{,}
    \DataTypeTok{breaks =} \DecValTok{20}\NormalTok{)}

\CommentTok{#Distribution of log(SalePrice)}

\KeywordTok{hist}\NormalTok{(}\KeywordTok{log}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice),}
    \DataTypeTok{xlab   =} \StringTok{"Sale Price with log(SalePrice)"}\NormalTok{,}
    \DataTypeTok{main   =} \StringTok{"Histogram of sales price"}\NormalTok{,}
    \DataTypeTok{border =} \StringTok{"blue"}\NormalTok{,}
    \DataTypeTok{breaks =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-16-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Q-Q Plot for SalePrice}

\KeywordTok{qqnorm}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice, }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot, without log(SalePrice)"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{)}
\KeywordTok{qqline}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\CommentTok{#Q-Q Plot for log(SalePrice)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{log}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot, with log(SalePrice) "}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{)}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{log}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice), }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-16-2.pdf}

From the above plot, we could see that the SalePrice data is
\texttt{right-skewed} so we can apply log transformation for SalePrice.

After applying \texttt{log\ transformation}, we could see that the
SalePrice is \texttt{normally\ distributed}.

\subsubsection{Distribution of numeric
varibles}\label{distribution-of-numeric-varibles}

In this section, we will explore the distribution of numeric variables
which have high correlation with SalePrice.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Histogram for checking the distribution of numeric variables}

\NormalTok{var_sel =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"YearBuilt"}\NormalTok{, }\StringTok{"YearRemodAdd"}\NormalTok{,}\StringTok{"TotalBsmtSF"}\NormalTok{, }\StringTok{"X1stFlrSF"}\NormalTok{,}\StringTok{"GrLivArea"}\NormalTok{, }\StringTok{"FullBath"}\NormalTok{, }\StringTok{"TotRmsAbvGrd"}\NormalTok{, }\StringTok{"GarageArea"}\NormalTok{)}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(var_sel))}
\KeywordTok{hist}\NormalTok{(house_trn[,var_sel[i]],}
    \DataTypeTok{xlab   =} \KeywordTok{paste}\NormalTok{(}\KeywordTok{toString}\NormalTok{(var_sel[i])),}
    \DataTypeTok{main   =} \KeywordTok{paste}\NormalTok{(}\StringTok{"Histogram of "}\NormalTok{,}\KeywordTok{toString}\NormalTok{(var_sel[i])),}
    \DataTypeTok{border =} \StringTok{"blue"}\NormalTok{,}
    \DataTypeTok{breaks =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-17-1.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-17-2.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-17-3.pdf}

From the above plots, we can infer the following - TotalBsmtSF is
\texttt{right-skewed} - GrLivArea is \texttt{right-skewed} - X1stFlrSF
is \texttt{right-skewed} - GarageArea is \texttt{right-skewed} -
YearBuilt is \texttt{left-skewed}

When we use the these variables which has right-skewedness, we can apply
log transformation for these variables.

\subsubsection{SalePrice Vs Factor
Variables}\label{saleprice-vs-factor-variables}

In this section, we can explore the effect of each factor variable on
SalePrice.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Box plot for factor variables against SalePrice }

\NormalTok{char_var =}\StringTok{ }\KeywordTok{as.array}\NormalTok{(}\KeywordTok{names}\NormalTok{(house_trn[, }\KeywordTok{sapply}\NormalTok{(house_trn, class) }\OperatorTok{==}\StringTok{ 'factor'}\NormalTok{]))}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(char_var))}
\KeywordTok{boxplot}\NormalTok{(house_trn}\OperatorTok{$}\NormalTok{SalePrice }\OperatorTok{~}\StringTok{ }\NormalTok{house_trn[,char_var[i]], }\DataTypeTok{data =}\NormalTok{ mpg,}
     \DataTypeTok{xlab   =} \KeywordTok{paste}\NormalTok{(}\KeywordTok{toString}\NormalTok{(char_var[i])),}
     \DataTypeTok{ylab   =} \StringTok{"Sales price"}\NormalTok{,}
     \DataTypeTok{main   =} \KeywordTok{paste}\NormalTok{(}\StringTok{"saleprice vs"}\NormalTok{, }\KeywordTok{toString}\NormalTok{(char_var[i])),}
     \DataTypeTok{pch    =} \DecValTok{20}\NormalTok{,}
     \DataTypeTok{cex    =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{las=}\DecValTok{1}\NormalTok{,}
     \DataTypeTok{outlier.size=}\DecValTok{10}\NormalTok{,}
     \DataTypeTok{col    =} \StringTok{"blue"}\NormalTok{,}
     \DataTypeTok{border =} \StringTok{"Black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-1.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-2.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-3.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-4.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-5.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-6.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-7.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-8.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-9.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-10.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-11.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-12.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-13.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-14.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-15.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-16.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-17.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-18.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-19.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-20.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-21.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-22.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-23.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-24.pdf}
\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-18-25.pdf}

From the above plots we could see that the below variable have
significance on SalePrice.

\begin{itemize}
\tightlist
\item
  MSSubClass
\item
  MSZoning
\item
  Neighborhood
\item
  OverallQual
\item
  KitchenQual
\end{itemize}

\subsection{Model Building}\label{model-building}

Based on the above data exploration, we will start building the model
with the variables which has high significane on Saleprice.

We will also put a log transformation for the SalePrice as it has right
skewedness, which we infered from the histogram plot in the data
exploration section.

\subsubsection{Additive Model}\label{additive-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add_mod =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(SalePrice) }\OperatorTok{~}\StringTok{  }\NormalTok{(MSSubClass }\OperatorTok{+}\NormalTok{GrLivArea }\OperatorTok{+}\StringTok{ }\NormalTok{TotalBsmtSF }\OperatorTok{+}\StringTok{ }\NormalTok{OverallQual}\OperatorTok{+}\StringTok{ }\NormalTok{YearBuilt}\OperatorTok{+}\StringTok{ }\NormalTok{FullBath }\OperatorTok{+}\StringTok{ }\NormalTok{YearRemodAdd }\OperatorTok{+}\StringTok{ }\NormalTok{Neighborhood }\OperatorTok{+}\NormalTok{TotRmsAbvGrd}\OperatorTok{+}\NormalTok{ExterQual), }\DataTypeTok{data =}\NormalTok{ house_trn)}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_add=}\KeywordTok{summary}\NormalTok{(add_mod)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8659282
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(add_mod), }\KeywordTok{resid}\NormalTok{(add_mod), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Data from Additive Model-1"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-21-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(add_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  add_mod
## BP = 386.15, df = 56, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(add_mod)
## W = 0.88892, p-value < 2.2e-16
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_Train_add =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1466346
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_test_add =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(add_mod,house_tst)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1674523
\end{verbatim}

\textbf{Discussion on test results for Additive model}

The above additive model have the following test results

\begin{itemize}
\item
  \(R^2\) value of 0.8659, ie 86.59\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{additive\ model}.
\item
  The model is
  \texttt{violating\ the\ constant\ variance\ and\ normality\ assumptions}
  which we could see from the QQ plot and fitted vs residual plot.The p
  values of \texttt{BP\ test} and \texttt{Shapiro-wilk\ test} also
  confirms the same.
\item
  Train RMSE of 0.1466
\item
  Test RMSE of 0.1675
\end{itemize}

This model is violating the model assumptions and have \(R^2\) value of
0.8659, we will do further analysis to find a model which doesn't
violate the model assumptions and have better \(R^2\).

\subsubsection{Additive Model 2}\label{additive-model-2}

In the above additive model, few variables like MSSubclass which doesn't
have significant p-value, so we will remove those non-significant
variables and fit another additive model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add_mod2 =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(SalePrice) }\OperatorTok{~}\StringTok{  }\NormalTok{(GrLivArea }\OperatorTok{+}\StringTok{ }\NormalTok{TotalBsmtSF }\OperatorTok{+}\StringTok{ }\NormalTok{OverallQual}\OperatorTok{+}\StringTok{ }\NormalTok{YearBuilt}\OperatorTok{+}\StringTok{ }\NormalTok{YearRemodAdd }\OperatorTok{+}\StringTok{ }\NormalTok{Neighborhood }\OperatorTok{+}\NormalTok{TotRmsAbvGrd}\OperatorTok{+}\NormalTok{ExterQual), }\DataTypeTok{data =}\NormalTok{ house_trn)}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_add2=}\KeywordTok{summary}\NormalTok{(add_mod2)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8560228
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(add_mod2), }\KeywordTok{resid}\NormalTok{(add_mod2), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Data from Additive Model-2"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod2), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod2), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-26-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(add_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  add_mod2
## BP = 361.98, df = 41, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(add_mod2)
## W = 0.89806, p-value < 2.2e-16
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_Train_add2 =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(add_mod2) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1519549
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_test_add2 =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(add_mod2,house_tst)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1739923
\end{verbatim}

\textbf{Discussion on test results for Additive model-2}

The above additive model have the following test results

\begin{itemize}
\item
  \(R^2\) value of 0.856, ie 85.60\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{additive\ model}.
\item
  The model is
  \texttt{violating\ the\ constant\ variance\ and\ normality\ assumptions}
  which we could see from the QQ plot and fitted vs residual plot.The p
  values of \texttt{BP\ test} and \texttt{Shapiro-wilk\ test} also
  confirms the same.
\item
  Train RMSE of 0.152
\item
  Test RMSE of 0.174
\end{itemize}

This model is also violating the model assumptions and have \(R^2\)
value of 0.856, which is lower than the previous model.We will do
further analysis to find a model which doesn't violate the model
assumptions and have better \(R^2\).

\paragraph{Anova of Additive Model 1 and Model
2}\label{anova-of-additive-model-1-and-model-2}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{anova}\NormalTok{(add_mod2,add_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: log(SalePrice) ~ (GrLivArea + TotalBsmtSF + OverallQual + YearBuilt + 
##     YearRemodAdd + Neighborhood + TotRmsAbvGrd + ExterQual)
## Model 2: log(SalePrice) ~ (MSSubClass + GrLivArea + TotalBsmtSF + OverallQual + 
##     YearBuilt + FullBath + YearRemodAdd + Neighborhood + TotRmsAbvGrd + 
##     ExterQual)
##   Res.Df    RSS Df Sum of Sq      F    Pr(>F)    
## 1   1126 26.970                                  
## 2   1111 25.114 15    1.8555 5.4722 8.087e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The annova test has low p-vlaue of 8.0865129\times 10\^{}\{-11\}, which
is confirming that the variable which we removed in additive model 2 is
not significant so we can continue to find a better model with the
variables in additive model-2.

\subsubsection{Log Interaction Model}\label{log-interaction-model}

The constant variance and normality assumptions are violated in the
above 2 additive models. The reason for this could be that the variables
have righ-skewedness, as we commonly say in statistics that the
\textbf{garbage in, garbage out}.

So we will try to fix the right-skewedness by applying log
transformation for the predictor variables.

We will also try some interaction and see, if the \(R^2\) is improving.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log_int_mod =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(SalePrice) }\OperatorTok{~}\StringTok{  }\NormalTok{(}\KeywordTok{log}\NormalTok{(GrLivArea)}\OperatorTok{+}\NormalTok{OverallQual}\OperatorTok{+}\StringTok{ }\NormalTok{YearBuilt}\OperatorTok{+}\StringTok{ }\NormalTok{YearRemodAdd }\OperatorTok{+}\StringTok{ }\NormalTok{Neighborhood }\OperatorTok{+}\KeywordTok{log}\NormalTok{(TotRmsAbvGrd)}\OperatorTok{+}\NormalTok{ExterQual)}\OperatorTok{^}\DecValTok{2}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ house_trn)}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_int=}\KeywordTok{summary}\NormalTok{(log_int_mod)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9138646
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(log_int_mod), }\KeywordTok{resid}\NormalTok{(log_int_mod), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Data from Log interaction model"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(log_int_mod), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(log_int_mod), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-32-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(log_int_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  log_int_mod
## BP = 266.21, df = 287, p-value = 0.8055
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(log_int_mod))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(log_int_mod)
## W = 0.96094, p-value < 2.2e-16
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_Train_log_int =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(log_int_mod) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1175327
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ (}\DataTypeTok{RMSE_test_log_int =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(log_int_mod,house_tst)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3491662
\end{verbatim}

\textbf{Discussion on test results for Log interaction Model}

The above log interaction model have the following test results

\begin{itemize}
\item
  \(R^2\) value of 0.9139, ie 91.39\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{additive\ model}.
\item
  The model is \texttt{violating\ the\ normality\ assumptions} but the
  \texttt{constant\ variance\ assumption\ is\ valid} which we could see
  from the QQ plot and fitted vs residual plot.The high p-value of
  \texttt{BP\ test} confirms the constant variance and low p-value of
  \texttt{Shapiro-wilk\ test} shows that the normality assumption is
  invalid.
\item
  Train RMSE of 0.1175
\item
  Test RMSE of 0.3492
\end{itemize}

Even though the constant variance is valid for the log interaction
model, its still violating the normality assumption and we see better
\(R^2\) value of 0.9139 compared to the other 2 additive models.

We will do further analysis and try to fit a model which doesn't violate
the model assumptions and still have better \(R^2\) as this model.

\subsubsection{Log Interation Model without Influential
data}\label{log-interation-model-without-influential-data}

To fix the normality assumption violation, we wil remove the influential
observations and fit the above model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Log Intearction Model}

\NormalTok{log_int_mod =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(SalePrice) }\OperatorTok{~}\StringTok{  }\NormalTok{(}\KeywordTok{log}\NormalTok{(GrLivArea)}\OperatorTok{+}\NormalTok{OverallQual}\OperatorTok{+}\StringTok{ }\NormalTok{YearBuilt}\OperatorTok{+}\StringTok{ }\NormalTok{YearRemodAdd }\OperatorTok{+}\StringTok{ }\NormalTok{Neighborhood }\OperatorTok{+}\KeywordTok{log}\NormalTok{(TotRmsAbvGrd)}\OperatorTok{+}\NormalTok{ExterQual)}\OperatorTok{^}\DecValTok{2}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ house_trn)}

\CommentTok{#Cooks distance for log interaction model}

\NormalTok{log_int_mod_cd =}\StringTok{ }\KeywordTok{cooks.distance}\NormalTok{(log_int_mod)}

\CommentTok{#Log interaction model after removing influential points}
   
\NormalTok{ int_add_cd_mod =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(SalePrice) }\OperatorTok{~}\StringTok{  }\NormalTok{(}\KeywordTok{log}\NormalTok{(GrLivArea)}\OperatorTok{+}\NormalTok{OverallQual}\OperatorTok{+}\NormalTok{YearBuilt }\OperatorTok{+}\StringTok{ }\NormalTok{YearRemodAdd }\OperatorTok{+}\StringTok{ }\NormalTok{Neighborhood }\OperatorTok{+}\KeywordTok{log}\NormalTok{(TotRmsAbvGrd)}\OperatorTok{+}\NormalTok{ExterQual)}\OperatorTok{^}\DecValTok{2}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ house_trn  , }\DataTypeTok{subset =}\NormalTok{ log_int_mod_cd }\OperatorTok{<}\StringTok{ }\DecValTok{4} \OperatorTok{/}\StringTok{ }\KeywordTok{length}\NormalTok{(log_int_mod_cd))}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_cd=}\KeywordTok{summary}\NormalTok{(int_add_cd_mod)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9294778
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(int_add_cd_mod), }\KeywordTok{resid}\NormalTok{(int_add_cd_mod), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Log interaction model - influential removed"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-37-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(int_add_cd_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  int_add_cd_mod
## BP = 209.4, df = 223, p-value = 0.7343
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(int_add_cd_mod)
## W = 0.99296, p-value = 0.0001155
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{RMSE_Train_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09258217
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ house_mod =}\StringTok{ }\KeywordTok{subset}\NormalTok{(house_tst, house_tst}\OperatorTok{$}\NormalTok{OverallQual }\OperatorTok{!=}\StringTok{ "2"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Blueste"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Veenker"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{ExterQual }\OperatorTok{!=}\StringTok{"Fa"}\NormalTok{ )}
 
\NormalTok{(}\DataTypeTok{RMSE_test_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(int_add_cd_mod,house_mod)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.336055
\end{verbatim}

\textbf{Discussion on test results - Log interaction model with
influential points removed}

The above log interaction model without influential points have the
following test results

\begin{itemize}
\item
  \(R^2\) value of 0.9295, ie 92.95\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{additive\ model}.
\item
  Normality assumptions and the constant variance assumptions is
  \textbf{valid} for this model which we could see from the QQ plot and
  fitted vs residual plot.The high p-value of \texttt{BP\ test} and
  \texttt{Shapiro-wilk\ test} confirms the same.
\item
  Train RMSE of 0.0926
\item
  Test RMSE of 1.3361
\end{itemize}

This model has improved \(R^2\) value and the model assumptions are also
valid but there 378 parameters, which will make the model interpretation
difficult.

Now, we will focus on \textbf{reducing the model parameters} by using
the AIC/BIC search methods.

\subsubsection{BIC of Log Interation
Model}\label{bic-of-log-interation-model}

In this section, we will do a BIC step search to reduce the number of
parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n =}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod))}

\NormalTok{BIC_Log_cd =}\StringTok{ }\KeywordTok{step}\NormalTok{(int_add_cd_mod,}\DataTypeTok{k=}\KeywordTok{log}\NormalTok{(n),}\DataTypeTok{trace=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_bic=}\KeywordTok{summary}\NormalTok{(BIC_Log_cd)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8883116
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(BIC_Log_cd), }\KeywordTok{resid}\NormalTok{(BIC_Log_cd), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Data from Model 2"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(BIC_Log_cd), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(BIC_Log_cd), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-42-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(BIC_Log_cd)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  BIC_Log_cd
## BP = 121.46, df = 39, p-value = 2.134e-10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(BIC_Log_cd))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(BIC_Log_cd)
## W = 0.99312, p-value = 0.0001453
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{RMSE_Train_BIC_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(BIC_Log_cd) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1165114
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ house_mod =}\StringTok{ }\KeywordTok{subset}\NormalTok{(house_tst, house_tst}\OperatorTok{$}\NormalTok{OverallQual }\OperatorTok{!=}\StringTok{ "2"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Blueste"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Veenker"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{ExterQual }\OperatorTok{!=}\StringTok{"Fa"}\NormalTok{ )}
 
\NormalTok{(}\DataTypeTok{RMSE_test_BIC_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(BIC_Log_cd,house_mod)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4877508
\end{verbatim}

\textbf{Discussion on test results for BIC search Model}

The above model built using BIC have the following test results

\begin{itemize}
\item
  \(R^2\) value of 0.8883, ie 88.83\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{BIC\ model}.
\item
  Normality assumptions and the constant variance assumptions are
  \textbf{not valid} for this model which we could see from the QQ plot
  and fitted vs residual plot.The low p-value of \texttt{BP\ test} and
  \texttt{Shapiro-wilk\ test} confirms the same.
\item
  Train RMSE of 0.1165
\item
  Test RMSE of 0.4878
\end{itemize}

This model has reduced \(R^2\) value compared to the log interaction
model and log interaction without influential points.But this model has
40parameters which is very less parameters compared to the log
interaction model, which make this model interpretable.

Now, we will see if we can use AIC search method to acheive below:

\begin{itemize}
\tightlist
\item
  Less parameters similar to BIC model
\item
  Better \(R^2\)
\item
  Valid model assumptions and
\item
  Low train and test RMSE
\end{itemize}

\subsubsection{AIC of Log Interation
Model}\label{aic-of-log-interation-model}

In this section, we will do a AIC step search to reduce the number of
parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n =}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{resid}\NormalTok{(int_add_cd_mod))}

\NormalTok{AIC_Log_cd =}\StringTok{ }\KeywordTok{step}\NormalTok{(int_add_cd_mod,}\DataTypeTok{trace=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{R-Squared}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{r2_aic=}\KeywordTok{summary}\NormalTok{(AIC_Log_cd)}\OperatorTok{$}\NormalTok{r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9229351
\end{verbatim}

\textbf{Q-Q and Fitted vs Residual Plot}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{fitted}\NormalTok{(AIC_Log_cd), }\KeywordTok{resid}\NormalTok{(AIC_Log_cd), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \DataTypeTok{xlab =} \StringTok{"Fitted"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Data from Model 2"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{0}\NormalTok{, }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}

\KeywordTok{qqnorm}\NormalTok{(}\KeywordTok{resid}\NormalTok{(AIC_Log_cd), }\DataTypeTok{main =} \StringTok{"Normal Q-Q Plot"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"darkgrey"}\NormalTok{,}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\KeywordTok{qqline}\NormalTok{(}\KeywordTok{resid}\NormalTok{(AIC_Log_cd), }\DataTypeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Data_Analysis_Project_files/figure-latex/unnamed-chunk-47-1.pdf}

\textbf{BP and Shapiro Test }

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(AIC_Log_cd)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  AIC_Log_cd
## BP = 171.21, df = 156, p-value = 0.1916
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{resid}\NormalTok{(AIC_Log_cd))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  resid(AIC_Log_cd)
## W = 0.99477, p-value = 0.001615
\end{verbatim}

\textbf{Test and Train RMSE}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{RMSE_Train_AIC_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{resid}\NormalTok{(AIC_Log_cd) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09678154
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ house_mod =}\StringTok{ }\KeywordTok{subset}\NormalTok{(house_tst, house_tst}\OperatorTok{$}\NormalTok{OverallQual }\OperatorTok{!=}\StringTok{ "2"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Blueste"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{Neighborhood }\OperatorTok{!=}\StringTok{"Veenker"} \OperatorTok{&}\StringTok{ }\NormalTok{house_tst}\OperatorTok{$}\NormalTok{ExterQual }\OperatorTok{!=}\StringTok{"Fa"}\NormalTok{ )}
 
\NormalTok{(}\DataTypeTok{RMSE_test_AIC_log_cd =} \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((}\KeywordTok{log}\NormalTok{(house_tst}\OperatorTok{$}\NormalTok{SalePrice) }\OperatorTok{-}\StringTok{ }\KeywordTok{predict}\NormalTok{(AIC_Log_cd,house_mod)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4985559
\end{verbatim}

\textbf{Discussion on test results for AIC search Model}

The above model built using AIC have the following test results

\begin{itemize}
\item
  \(R^2\) value of 0.9229, ie 92.29\% of the variance in SalePrice is
  explained by linear relationship with variables in the
  \texttt{BIC\ model}.
\item
  Normality assumptions and the constant variance assumptions are
  \textbf{valid} for this model which we could see from the QQ plot and
  fitted vs residual plot. The high p-value of \texttt{BP\ test} and
  \texttt{Shapiro-wilk\ test} confirms the same.
\item
  Train RMSE of 0.0968
\item
  Test RMSE of 0.4986
\end{itemize}

Also, this model has better \(R^2\) value and this model has
274parameters which is less parameters compared to the log interaction
model, which make this model more interpretable than the log interaction
model.

\subsection{Results and Prediction}\label{results-and-prediction}

\textbf{Preferred model for predicting SalePrice}

Based on the discussion points about \(R^2\), RMSE and model assumption
discussed in each model section and from the table below we could see
that, the model built using the AIC search with log interaction
model(\textbf{AIC\_Log\_cd}) is comparitively the good model for
predicting the house SalePrice as it has the best \(R^2\) of the 6
models built above and it has comparitively good test RMSE.

\begin{longtable}[]{@{}lrrr@{}}
\toprule
Models & R2 Values & Train RMSE & Test RMSE\tabularnewline
\midrule
\endhead
add\_mod & 0.8659282 & 0.1466346 & 0.1674523\tabularnewline
add\_mod2 & 0.8560228 & 0.1519549 & 0.1739923\tabularnewline
log\_int\_mod & 0.9138646 & 0.1175327 & 0.3491662\tabularnewline
int\_add\_cd\_mod & 0.9294778 & 0.0925822 & 1.3360547\tabularnewline
BIC\_Log\_cd & 0.8883116 & 0.1165114 & 0.4877508\tabularnewline
AIC\_Log\_cd & 0.9229351 & 0.0967815 & 0.4985559\tabularnewline
\bottomrule
\end{longtable}

The AIC log interaction model also has valid constant variance and
normality assumption, which makes the model good for interpretation
purpose but it may be little difficuly to use the AIC\_Log\_cd model for
interpretation, as it has large number of parameters.

The aim of this project is to build a priction model,usually if we are
building a models for prediction purpose we can select the model based
on the \(R^2\) and RMSE values alone as the model will be good for
prediction and we shouldn't be concerned about the number of parameter.

\textbf{Prediction on test data}

Using our preferred model, lets predict the SalesPrice for the houses in
'Gilbert` neigborhood in test data set and see if the predicted price is
matching with the similar kind of house in training data set.

\textbf{Predicted SalePrice for houses in Gilbert Neighborhood}

\begin{longtable}[]{@{}lrrlrrlrlr@{}}
\toprule
& GrLivArea & GarageArea & OverallQual & YearBuilt & YearRemodAdd &
Neighborhood & TotRmsAbvGrd & ExterQual & SalePrice\tabularnewline
\midrule
\endhead
1463 & 1629 & 482 & 5 & 1997 & 1998 & Gilbert & 6 & TA &
144977.4\tabularnewline
1464 & 1604 & 470 & 6 & 1998 & 1998 & Gilbert & 7 & TA &
180924.6\tabularnewline
1466 & 1655 & 440 & 6 & 1993 & 1994 & Gilbert & 7 & TA &
176284.2\tabularnewline
1467 & 1187 & 420 & 6 & 1992 & 2007 & Gilbert & 6 & TA &
160625.6\tabularnewline
1468 & 1465 & 393 & 6 & 1998 & 1998 & Gilbert & 7 & TA &
175115.1\tabularnewline
1469 & 1341 & 506 & 7 & 1990 & 1990 & Gilbert & 5 & TA &
162938.6\tabularnewline
1483 & 1324 & 430 & 6 & 2005 & 2005 & Gilbert & 6 & Gd &
169230.6\tabularnewline
1485 & 1374 & 400 & 7 & 2004 & 2004 & Gilbert & 7 & Gd &
181816.4\tabularnewline
1486 & 1733 & 433 & 7 & 2004 & 2004 & Gilbert & 7 & Gd &
207771.2\tabularnewline
1627 & 1608 & 470 & 6 & 1997 & 1997 & Gilbert & 7 & TA &
179627.4\tabularnewline
\bottomrule
\end{longtable}

\textbf{Real SalePrice for houses in Gilbert Neighborhood from train
data}

\begin{longtable}[]{@{}lrrlrrlrlr@{}}
\toprule
& GrLivArea & GarageArea & OverallQual & YearBuilt & YearRemodAdd &
Neighborhood & TotRmsAbvGrd & ExterQual & SalePrice\tabularnewline
\midrule
\endhead
51 & 1470 & 388 & 6 & 1997 & 1997 & Gilbert & 6 & TA &
177000\tabularnewline
73 & 1718 & 427 & 7 & 1998 & 1998 & Gilbert & 7 & TA &
185000\tabularnewline
85 & 1474 & 400 & 7 & 1995 & 1996 & Gilbert & 7 & TA &
168500\tabularnewline
87 & 1560 & 400 & 6 & 2005 & 2005 & Gilbert & 6 & Gd &
174000\tabularnewline
96 & 1470 & 420 & 6 & 1993 & 1993 & Gilbert & 6 & Ex &
185000\tabularnewline
112 & 1430 & 400 & 7 & 2000 & 2000 & Gilbert & 7 & TA &
180000\tabularnewline
132 & 2054 & 390 & 6 & 2000 & 2000 & Gilbert & 7 & Gd &
244000\tabularnewline
148 & 2035 & 434 & 7 & 2001 & 2001 & Gilbert & 8 & Gd &
222500\tabularnewline
160 & 2462 & 576 & 7 & 2005 & 2006 & Gilbert & 9 & Gd &
320000\tabularnewline
169 & 1720 & 440 & 7 & 2004 & 2004 & Gilbert & 7 & Gd &
183500\tabularnewline
\bottomrule
\end{longtable}

\textbf{Conclusion}

From the above tables, we could see that the Saleprice predicted from
the test data set for the houses in Gilbert neighborhood are having
values close to that of the saleprice of houses in Gilbert neighborhood
in the train dataset. So our model is doing a pretty job in predicting
the SalePrice.


\end{document}
